2023-08-02T14:01:32,896271021+00:00 - rsyslog/run 
2023-08-02T14:01:32,910521721+00:00 - gunicorn/run 
2023-08-02T14:01:32,917104221+00:00 | gunicorn/run | 
2023-08-02T14:01:32,922746821+00:00 | gunicorn/run | ###############################################
2023-08-02T14:01:32,926485021+00:00 | gunicorn/run | AzureML Container Runtime Information
2023-08-02T14:01:32,933504821+00:00 | gunicorn/run | ###############################################
2023-08-02T14:01:32,937577321+00:00 | gunicorn/run | 
2023-08-02T14:01:32,947168221+00:00 - nginx/run 
2023-08-02T14:01:32,949026521+00:00 | gunicorn/run | 
2023-08-02T14:01:32,970673121+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20230628.v2
2023-08-02T14:01:32,976497721+00:00 | gunicorn/run | 
2023-08-02T14:01:32,983367421+00:00 | gunicorn/run | 
2023-08-02T14:01:32,989733921+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml-automl/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
2023-08-02T14:01:32,997485121+00:00 | gunicorn/run | PYTHONPATH environment variable: 
2023-08-02T14:01:33,005129021+00:00 | gunicorn/run | 
2023-08-02T14:01:34,414407521+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda

# conda environments:
#
                         /azureml-envs/azureml-automl
base                     /opt/miniconda

2023-08-02T14:01:35,424345421+00:00 | gunicorn/run | 
2023-08-02T14:01:35,426022721+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)

adal==1.2.7
applicationinsights==0.11.10
arch==5.3.1
argcomplete==2.1.2
argon2-cffi==21.3.0
argon2-cffi-bindings==21.2.0
asttokens==2.2.1
attrs==23.1.0
azure-common==1.1.28
azure-core==1.27.1
azure-graphrbac==0.61.1
azure-identity==1.13.0
azure-mgmt-authorization==3.0.0
azure-mgmt-containerregistry==10.1.0
azure-mgmt-core==1.4.0
azure-mgmt-keyvault==10.2.2
azure-mgmt-resource==22.0.0
azure-mgmt-storage==21.0.0
azure-storage-blob==12.13.0
azure-storage-queue==12.6.0
azureml-automl-core==1.52.0.post1
azureml-automl-runtime==1.52.0.post1
azureml-core==1.52.0
azureml-dataprep==4.11.4
azureml-dataprep-native==38.0.0
azureml-dataprep-rslex==2.18.4
azureml-dataset-runtime==1.52.0
azureml-defaults==1.52.0
azureml-inference-server-http==0.8.4
azureml-interpret==1.52.0
azureml-mlflow==1.52.0
azureml-pipeline-core==1.52.0
azureml-responsibleai==1.52.0
azureml-telemetry==1.52.0
azureml-train-automl-client==1.52.0
azureml-train-automl-runtime==1.52.0
azureml-train-core==1.52.0
azureml-train-restclients-hyperdrive==1.52.0
azureml-training-tabular==1.52.0
backcall==0.2.0
backports.tempfile==1.0
backports.weakref==1.0.post1
bcrypt==4.0.1
beautifulsoup4==4.12.2
bleach==6.0.0
bokeh==2.4.3
boto==2.49.0
boto3==1.20.19
botocore==1.23.19
Brotli @ file:///home/conda/feedstock_root/build_artifacts/brotli-split_1687884021435/work
cachetools==5.3.1
certifi==2023.5.7
cffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1671179356964/work
charset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1678108872112/work
click==8.1.4
cloudpickle @ file:///home/conda/feedstock_root/build_artifacts/cloudpickle_1598400192773/work
cmdstanpy==0.9.5
contextlib2==21.6.0
contourpy==1.1.0
convertdate @ file:///home/conda/feedstock_root/build_artifacts/convertdate_1642883757836/work
cryptography==41.0.0
cycler==0.11.0
Cython==0.29.17
dask==2023.2.0
databricks-cli==0.17.7
dataclasses==0.6
debugpy==1.6.7
decorator==5.1.1
defusedxml==0.7.1
dice-ml==0.9
dill==0.3.6
distributed==2023.2.0
distro==1.8.0
docker==6.1.3
dotnetcore2==3.1.23
econml==0.14.1
entrypoints==0.4
ephem==4.1.4
erroranalysis==0.4.4
executing==1.2.0
fairlearn==0.8.0
fastjsonschema==2.17.1
fbprophet==0.7.1
fire==0.5.0
Flask==2.2.5
Flask-Cors==3.0.10
flatbuffers==23.5.26
fonttools==4.40.0
fsspec==2023.6.0
fusepy==3.0.1
gensim==3.8.3
gitdb==4.0.10
GitPython==3.1.31
google-api-core==2.11.1
google-auth==2.21.0
googleapis-common-protos==1.59.1
gunicorn==20.1.0
h5py==3.9.0
holidays @ file:///home/conda/feedstock_root/build_artifacts/holidays_1595448845196/work
humanfriendly==10.0
idna @ file:///home/conda/feedstock_root/build_artifacts/idna_1663625384323/work
importlib-metadata==6.8.0
importlib-resources==5.13.0
inference-schema==1.5.1
interpret-community==0.29.0
interpret-core==0.3.2
ipykernel==6.8.0
ipython==8.12.2
ipython-genutils==0.2.0
isodate==0.6.1
itsdangerous==2.1.2
jedi==0.18.2
jeepney==0.8.0
Jinja2==3.1.2
jmespath==0.10.0
joblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1663332044897/work
jsonpickle==3.0.1
jsonschema==4.18.0
jsonschema-specifications==2023.6.1
jupyter_client==7.4.9
jupyter_core==5.3.1
jupyterlab-pygments==0.2.2
keras2onnx==1.6.0
kiwisolver==1.4.4
knack==0.10.1
korean-lunar-calendar @ file:///home/conda/feedstock_root/build_artifacts/korean_lunar_calendar_1663341251025/work
lightgbm==3.2.1
llvmlite==0.38.1
locket==1.0.0
LunarCalendar==0.0.9
MarkupSafe==2.1.2
matplotlib==3.7.2
matplotlib-inline==0.1.6
mistune==3.0.1
ml-wrappers==0.4.11
mlflow-skinny==2.4.1
mltable==1.4.1
msal==1.22.0
msal-extensions==1.0.0
msgpack==1.0.5
msrest==0.7.1
msrestazure==0.6.4
nbclient==0.8.0
nbconvert==7.6.0
nbformat==5.9.0
ndg-httpsclient==0.5.1
nest-asyncio==1.5.6
networkx==2.5
notebook==6.4.9
numba==0.55.2
numpy==1.22.3
oauthlib==3.2.2
onnx==1.13.1
onnxconverter-common==1.6.0
onnxmltools==1.4.1
onnxruntime==1.11.1
opencensus==0.11.2
opencensus-context==0.1.3
opencensus-ext-azure==1.1.9
packaging==23.0
pandas==1.1.5
pandocfilters==1.5.0
paramiko==3.2.0
parso==0.8.3
partd==1.4.0
pathspec==0.11.1
patsy==0.5.3
pexpect==4.8.0
pickleshare==0.7.5
Pillow==10.0.0
pkginfo==1.9.6
pkgutil_resolve_name==1.3.10
platformdirs @ file:///home/conda/feedstock_root/build_artifacts/platformdirs_1688739404342/work
pmdarima==1.8.0
pooch @ file:///home/conda/feedstock_root/build_artifacts/pooch_1679580333621/work
portalocker==2.7.0
prometheus-client==0.17.0
prompt-toolkit==3.0.39
property-cached==1.6.4
protobuf==3.20.3
psutil @ file:///home/conda/feedstock_root/build_artifacts/psutil_1681775007745/work
ptyprocess==0.7.0
pure-eval==0.2.2
py-cpuinfo==5.0.0
pyarrow==9.0.0
pyasn1==0.5.0
pyasn1-modules==0.3.0
pycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1636257122734/work
pydantic==1.10.11
Pygments==2.15.1
PyJWT==2.7.0
PyMeeus @ file:///home/conda/feedstock_root/build_artifacts/pymeeus_1670868433998/work
PyNaCl==1.5.0
pyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1685514481738/work
pyparsing==3.0.9
PySocks @ file:///home/conda/feedstock_root/build_artifacts/pysocks_1661604839144/work
pystan==2.19.1.1
python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work
pytz @ file:///home/conda/feedstock_root/build_artifacts/pytz_1680088766131/work
PyYAML==6.0
pyzmq==25.1.0
raiutils==0.4.0
referencing==0.29.1
requests @ file:///home/conda/feedstock_root/build_artifacts/requests_1684774241324/work
requests-oauthlib==1.3.1
responsibleai==0.28.0
rpds-py==0.8.8
rsa==4.9
s3transfer==0.5.2
scikit-learn==0.22.1
scipy==1.5.3
SecretStorage==3.3.3
semver==2.13.0
Send2Trash==1.8.2
setuptools-git==1.2
shap==0.41.0
six @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work
skl2onnx==1.4.9
sklearn-pandas==1.7.0
slicer==0.0.7
smart-open==1.9.0
smmap==5.0.0
sortedcontainers==2.4.0
soupsieve==2.4.1
sparse==0.14.0
sqlparse==0.4.4
stack-data==0.6.2
statsmodels==0.11.1
tabulate==0.9.0
tblib==2.0.0
termcolor==2.3.0
terminado==0.17.1
tinycss2==1.2.1
toolz==0.12.0
tornado==6.3.2
tqdm==4.65.0
traitlets==5.9.0
typing_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1688315532570/work
urllib3==1.26.16
wcwidth==0.2.6
webencodings==0.5.1
websocket-client==1.6.1
Werkzeug==2.3.6
wrapt==1.12.1
xgboost==1.3.3
zict==3.0.0
zipp==3.15.0

2023-08-02T14:01:38,274086794+00:00 | gunicorn/run | 
2023-08-02T14:01:38,279700325+00:00 | gunicorn/run | ###############################################
2023-08-02T14:01:38,285244054+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed
2023-08-02T14:01:38,289284348+00:00 | gunicorn/run | ###############################################
2023-08-02T14:01:38,296974627+00:00 | gunicorn/run | 
2023-08-02T14:01:41,581352756+00:00 | gunicorn/run | 
2023-08-02T14:01:41,589032435+00:00 | gunicorn/run | ###############################################
2023-08-02T14:01:41,591662096+00:00 | gunicorn/run | AzureML Inference Server
2023-08-02T14:01:41,594376959+00:00 | gunicorn/run | ###############################################
2023-08-02T14:01:41,596998120+00:00 | gunicorn/run | 
2023-08-02T14:01:45,144694709+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.
2023-08-02 14:01:45,545 I [78] azmlinfsrv - Loaded logging config from /azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/logging.json
2023-08-02 14:01:45,851 I [78] gunicorn.error - Starting gunicorn 20.1.0
2023-08-02 14:01:45,851 I [78] gunicorn.error - Listening at: http://0.0.0.0:31311 (78)
2023-08-02 14:01:45,851 I [78] gunicorn.error - Using worker: sync
2023-08-02 14:01:45,855 I [146] gunicorn.error - Booting worker with pid: 146
Valid Application Insights instrumentation key provided.

Azure ML Inferencing HTTP server v0.8.4


Server Settings
---------------
Entry Script Name: /var/azureml-app/main.py
Model Directory: /var/azureml-app/azureml-models/AutoMLe98a50a1652/1
Config File: None
Worker Count: 1
Worker Timeout (seconds): 300
Server Port: 31311
Health Port: 31311
Application Insights Enabled: true
Application Insights Key: AppInsights key provided
Inferencing HTTP server version: azmlinfsrv/0.8.4
CORS for the specified origins: None
Create dedicated endpoint for health: None


Server Routes
---------------
Liveness Probe: GET   127.0.0.1:31311/
Score:          POST  127.0.0.1:31311/score

/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/config.py:51: FutureWarning: aliases are no longer used by BaseSettings to define which environment variables to read. Instead use the "env" field setting. See https://pydantic-docs.helpmanual.io/usage/settings/#environment-variable-names
  class AMLInferenceServerConfig(pydantic.BaseSettings):
2023-08-02 14:01:47,229 I [146] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.
Initializing logger
2023-08-02 14:01:47,235 I [146] azmlinfsrv - Starting up app insights client
WARNING:opencensus.ext.azure.common:DeprecationWarning: Explicitly using instrumentation key isdeprecated. Please use a connection string instead.
WARNING:opencensus.ext.azure.common:DeprecationWarning: Explicitly using instrumentation key isdeprecated. Please use a connection string instead.
WARNING:opencensus.ext.azure.common:DeprecationWarning: Explicitly using instrumentation key isdeprecated. Please use a connection string instead.
2023-08-02 14:01:54,131 I [146] azmlinfsrv.user_script - Found user script at /var/azureml-app/main.py
2023-08-02 14:01:54,132 I [146] azmlinfsrv.user_script - run() is decorated with @input_schema. Server will invoke it with the following arguments: Inputs, GlobalParameters.
2023-08-02 14:01:54,132 I [146] azmlinfsrv.user_script - Invoking user's init function
ERROR:fbprophet.plot:Importing plotly failed. Interactive plots will not work.
2023-08-02 14:02:14,748 I [146] azmlinfsrv.user_script - Users's init has completed successfully
2023-08-02 14:02:14,790 I [146] azmlinfsrv.swagger - Swaggers are prepared for the following versions: [2, 3, 3.1].
2023-08-02 14:02:14,791 I [146] azmlinfsrv - Scoring timeout is set to 60000
2023-08-02 14:02:14,809 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.
2023-08-02 14:02:14,813 I [146] gunicorn.access - 127.0.0.1 - - [02/Aug/2023:14:02:14 +0000] "GET / HTTP/1.0" 200 7 "-" "Go-http-client/1.1"
2023-08-02 14:02:14,823 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.
2023-08-02 14:02:14,826 I [146] azmlinfsrv - GET /swagger.json 200 1.390ms 4267
2023-08-02 14:02:14,833 I [146] gunicorn.access - 127.0.0.1 - - [02/Aug/2023:14:02:14 +0000] "GET /swagger.json HTTP/1.0" 200 4267 "-" "Go-http-client/1.1"
2023-08-02 14:04:23,206 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.
2023-08-02 14:04:23,208 I [146] gunicorn.access - 127.0.0.1 - - [02/Aug/2023:14:04:23 +0000] "GET / HTTP/1.0" 200 7 "-" "Go-http-client/1.1"
2023-08-02 14:04:23,215 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.
2023-08-02 14:04:23,216 I [146] azmlinfsrv - GET /swagger.json 200 1.280ms 4267
2023-08-02 14:04:23,219 I [146] gunicorn.access - 127.0.0.1 - - [02/Aug/2023:14:04:23 +0000] "GET /swagger.json HTTP/1.0" 200 4267 "-" "Go-http-client/1.1"
2023-08-02 14:19:11,083 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.
2023-08-02 14:19:11,087 I [146] azmlinfsrv - GET /swagger.json 200 3.577ms 4267
2023-08-02 14:19:11,101 I [146] gunicorn.access - 127.0.0.1 - - [02/Aug/2023:14:19:11 +0000] "GET /swagger.json HTTP/1.0" 200 4267 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36"
2023-08-02 14:25:21,792 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.
2023-08-02 14:25:21,801 I [146] gunicorn.access - 127.0.0.1 - - [02/Aug/2023:14:25:21 +0000] "GET / HTTP/1.0" 200 7 "-" "Go-http-client/1.1"
2023-08-02 14:29:00,705 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.
2023-08-02 14:29:00,705 I [146] azmlinfsrv - GET /swagger.json 200 0.775ms 4267
2023-08-02 14:29:00,707 I [146] gunicorn.access - 127.0.0.1 - - [02/Aug/2023:14:29:00 +0000] "GET /swagger.json HTTP/1.0" 200 4267 "-" "Go-http-client/1.1"
2023-08-02 14:30:32,954 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.
2023-08-02 14:30:32,956 I [146] azmlinfsrv - POST /score 400 1.848ms 66
2023-08-02 14:30:32,963 I [146] gunicorn.access - 127.0.0.1 - - [02/Aug/2023:14:30:32 +0000] "POST /score HTTP/1.0" 400 66 "-" "python-requests/2.24.0"
2023-08-02 14:31:51,865 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.
2023-08-02 14:31:51,874 E [146] azmlinfsrv.trace - (<class 'azureml_inference_server_http.server.user_script.UserScriptException'>, UserScriptException('Caught an unhandled exception from the user script'), <traceback object at 0x7f96ed657600>)
Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 130, in invoke_run
    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 154, in <lambda>
    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 62, in decorator_input
    return user_run(*args, **kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 58, in decorator_input
    kwargs[param_name] = _deserialize_input_argument(kwargs[param_name], param_type, param_name)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 324, in _deserialize_input_argument
    raise ValueError("Invalid input data type to parse. Expected: {0} but got {1}".format(
ValueError: Invalid input data type to parse. Expected: <class 'dict'> but got <class 'list'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py", line 219, in handle_score
    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 137, in invoke_run
    raise UserScriptException(ex) from ex
azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script
2023-08-02 14:31:51,889 E [146] azmlinfsrv - Encountered Exception: Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 130, in invoke_run
    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 154, in <lambda>
    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 62, in decorator_input
    return user_run(*args, **kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 58, in decorator_input
    kwargs[param_name] = _deserialize_input_argument(kwargs[param_name], param_type, param_name)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 324, in _deserialize_input_argument
    raise ValueError("Invalid input data type to parse. Expected: {0} but got {1}".format(
ValueError: Invalid input data type to parse. Expected: <class 'dict'> but got <class 'list'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py", line 219, in handle_score
    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 137, in invoke_run
    raise UserScriptException(ex) from ex
azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script

2023-08-02 14:31:51,889 I [146] azmlinfsrv - POST /score 500 23.784ms 92
2023-08-02 14:31:51,891 I [146] gunicorn.access - 127.0.0.1 - - [02/Aug/2023:14:31:51 +0000] "POST /score HTTP/1.0" 500 92 "-" "python-requests/2.24.0"
2023-08-02 14:32:23,694 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.
2023-08-02 14:32:23,696 E [146] azmlinfsrv.trace - (<class 'azureml_inference_server_http.server.user_script.UserScriptException'>, UserScriptException('Caught an unhandled exception from the user script'), <traceback object at 0x7f96ed5f8b40>)
Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 130, in invoke_run
    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 154, in <lambda>
    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 62, in decorator_input
    return user_run(*args, **kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 58, in decorator_input
    kwargs[param_name] = _deserialize_input_argument(kwargs[param_name], param_type, param_name)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 324, in _deserialize_input_argument
    raise ValueError("Invalid input data type to parse. Expected: {0} but got {1}".format(
ValueError: Invalid input data type to parse. Expected: <class 'dict'> but got <class 'list'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py", line 219, in handle_score
    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 137, in invoke_run
    raise UserScriptException(ex) from ex
azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script
2023-08-02 14:32:23,698 E [146] azmlinfsrv - Encountered Exception: Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 130, in invoke_run
    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 154, in <lambda>
    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 62, in decorator_input
    return user_run(*args, **kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 58, in decorator_input
    kwargs[param_name] = _deserialize_input_argument(kwargs[param_name], param_type, param_name)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 324, in _deserialize_input_argument
    raise ValueError("Invalid input data type to parse. Expected: {0} but got {1}".format(
ValueError: Invalid input data type to parse. Expected: <class 'dict'> but got <class 'list'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py", line 219, in handle_score
    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 137, in invoke_run
    raise UserScriptException(ex) from ex
azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script

2023-08-02 14:32:23,699 I [146] azmlinfsrv - POST /score 500 4.997ms 92
2023-08-02 14:32:23,701 I [146] gunicorn.access - 127.0.0.1 - - [02/Aug/2023:14:32:23 +0000] "POST /score HTTP/1.0" 500 92 "-" "python-requests/2.24.0"
2023-08-02 15:09:29,610 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.
2023-08-02 15:09:29,611 I [146] gunicorn.access - 127.0.0.1 - - [02/Aug/2023:15:09:29 +0000] "GET / HTTP/1.0" 200 7 "-" "Go-http-client/1.1"
2023-08-02 15:22:28,614 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.
2023-08-02 15:22:28,616 E [146] azmlinfsrv.trace - (<class 'azureml_inference_server_http.server.user_script.UserScriptException'>, UserScriptException('Caught an unhandled exception from the user script'), <traceback object at 0x7f96ed5fbec0>)
Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 130, in invoke_run
    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 154, in <lambda>
    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 62, in decorator_input
    return user_run(*args, **kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 58, in decorator_input
    kwargs[param_name] = _deserialize_input_argument(kwargs[param_name], param_type, param_name)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 324, in _deserialize_input_argument
    raise ValueError("Invalid input data type to parse. Expected: {0} but got {1}".format(
ValueError: Invalid input data type to parse. Expected: <class 'dict'> but got <class 'list'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py", line 219, in handle_score
    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 137, in invoke_run
    raise UserScriptException(ex) from ex
azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script
2023-08-02 15:22:28,619 E [146] azmlinfsrv - Encountered Exception: Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 130, in invoke_run
    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 154, in <lambda>
    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 62, in decorator_input
    return user_run(*args, **kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 58, in decorator_input
    kwargs[param_name] = _deserialize_input_argument(kwargs[param_name], param_type, param_name)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 324, in _deserialize_input_argument
    raise ValueError("Invalid input data type to parse. Expected: {0} but got {1}".format(
ValueError: Invalid input data type to parse. Expected: <class 'dict'> but got <class 'list'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py", line 219, in handle_score
    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 137, in invoke_run
    raise UserScriptException(ex) from ex
azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script

2023-08-02 15:22:28,622 I [146] azmlinfsrv - POST /score 500 8.447ms 92
2023-08-02 15:22:28,624 I [146] gunicorn.access - 127.0.0.1 - - [02/Aug/2023:15:22:28 +0000] "POST /score HTTP/1.0" 500 92 "-" "python-requests/2.24.0"
2023-08-02 16:13:05,342 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.
2023-08-02 16:13:05,345 E [146] azmlinfsrv.trace - (<class 'azureml_inference_server_http.server.user_script.UserScriptException'>, UserScriptException('Caught an unhandled exception from the user script'), <traceback object at 0x7f96ed5ff240>)
Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 130, in invoke_run
    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 154, in <lambda>
    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 62, in decorator_input
    return user_run(*args, **kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 58, in decorator_input
    kwargs[param_name] = _deserialize_input_argument(kwargs[param_name], param_type, param_name)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 324, in _deserialize_input_argument
    raise ValueError("Invalid input data type to parse. Expected: {0} but got {1}".format(
ValueError: Invalid input data type to parse. Expected: <class 'dict'> but got <class 'list'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py", line 219, in handle_score
    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 137, in invoke_run
    raise UserScriptException(ex) from ex
azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script
2023-08-02 16:13:05,347 E [146] azmlinfsrv - Encountered Exception: Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 130, in invoke_run
    run_output = self._wrapped_user_run(**run_parameters, request_headers=dict(request.headers))
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 154, in <lambda>
    self._wrapped_user_run = lambda request_headers, **kwargs: self._user_run(**kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 62, in decorator_input
    return user_run(*args, **kwargs)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 58, in decorator_input
    kwargs[param_name] = _deserialize_input_argument(kwargs[param_name], param_type, param_name)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/inference_schema/schema_decorators.py", line 324, in _deserialize_input_argument
    raise ValueError("Invalid input data type to parse. Expected: {0} but got {1}".format(
ValueError: Invalid input data type to parse. Expected: <class 'dict'> but got <class 'list'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/routes.py", line 219, in handle_score
    timed_result = main_blueprint.user_script.invoke_run(request, timeout_ms=config.scoring_timeout)
  File "/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/user_script.py", line 137, in invoke_run
    raise UserScriptException(ex) from ex
azureml_inference_server_http.server.user_script.UserScriptException: Caught an unhandled exception from the user script

2023-08-02 16:13:05,349 I [146] azmlinfsrv - POST /score 500 7.473ms 92
2023-08-02 16:13:05,353 I [146] gunicorn.access - 127.0.0.1 - - [02/Aug/2023:16:13:05 +0000] "POST /score HTTP/1.0" 500 92 "-" "python-requests/2.24.0"
2023-08-02 16:13:50,512 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.
2023-08-02 16:13:50,518 I [146] gunicorn.access - 127.0.0.1 - - [02/Aug/2023:16:13:50 +0000] "GET / HTTP/1.0" 200 7 "-" "Go-http-client/1.1"
2023-08-02 16:13:50,526 W [146] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.
2023-08-02 16:13:50,527 I [146] azmlinfsrv - GET /swagger.json 200 1.427ms 4267
2023-08-02 16:13:50,529 I [146] gunicorn.access - 127.0.0.1 - - [02/Aug/2023:16:13:50 +0000] "GET /swagger.json HTTP/1.0" 200 4267 "-" "Go-http-client/1.1"